{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - The IRLS algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the optimization process with x_0: 1\n",
      "Step 0: 1.6420926159343308\n",
      "Step 1: 1.5706752771612507\n",
      "Step 2: 1.5707963267954879\n",
      "Step 3: 1.5707963267948966\n",
      "Step 4: 1.5707963267948966\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.1.1\n",
    "\n",
    "## See also: https://docs.sympy.org/latest/tutorial/calculus.html\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "def iterative_optimization(x):\n",
    "    \"\"\" Using Newton-Raphson iterative optimization scheme \"\"\"\n",
    "    return x + (np.cos(x)/np.sin(x))\n",
    "\n",
    "x_t = 1\n",
    "n_iterations = 5\n",
    "\n",
    "print(\"Starting the optimization process with x_0: {}\".format(x_t))\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    x_t = iterative_optimization(x_t)\n",
    "    print(\"Step {}: {}\".format(i, x_t))\n",
    "    \n",
    "# Starting the optimization process with x_0: 1\n",
    "# Step 0: 1.6420926159343308\n",
    "# Step 1: 1.5706752771612507\n",
    "# Step 2: 1.5707963267954879\n",
    "# Step 3: 1.5707963267948966\n",
    "# Step 4: 1.5707963267948966\n",
    "\n",
    "# Starting the optimization process with x_0: -1\n",
    "# Step 0: -1.6420926159343308\n",
    "# Step 1: -1.5706752771612507\n",
    "# Step 2: -1.5707963267954879\n",
    "# Step 3: -1.5707963267948966\n",
    "# Step 4: -1.5707963267948966\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.78583498]\n",
      " [0.80845465]\n",
      " [0.81153267]\n",
      " [0.83201839]], \n",
      "current_gradient=[[1.23784069]\n",
      " [0.7039866 ]], \n",
      "current_hessian=[[0.61586527 0.2728401 ]\n",
      " [0.2728401  0.12780555]], \n",
      "w=[[  8.93409151]\n",
      " [-21.44601155]]\n",
      "\n",
      "Iteration 1: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.92416201]\n",
      " [0.3770347 ]\n",
      " [0.28270691]\n",
      " [0.01919892]], \n",
      "current_gradient=[[-0.39689745]\n",
      " [-0.17529159]], \n",
      "current_hessian=[[0.52658017 0.22895168]\n",
      " [0.22895168 0.10146842]], \n",
      "w=[[  9.0716414 ]\n",
      " [-20.02882864]]\n",
      "\n",
      "Iteration 2: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.95534016]\n",
      " [0.56437983]\n",
      " [0.46465411]\n",
      " [0.04994223]], \n",
      "current_gradient=[[0.03431634]\n",
      " [0.01863541]], \n",
      "current_hessian=[[0.58471925 0.26387002]\n",
      " [0.26387002 0.12115438]], \n",
      "w=[[  9.69751114]\n",
      " [-21.54576651]]\n",
      "\n",
      "Iteration 3: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.96208592]\n",
      " [0.55413049]\n",
      " [0.44681658]\n",
      " [0.03805412]], \n",
      "current_gradient=[[0.00108711]\n",
      " [0.00081129]], \n",
      "current_hessian=[[0.56732402 0.25531624]\n",
      " [0.25531624 0.11659528]], \n",
      "w=[[  9.78116385]\n",
      " [-21.73590446]]\n",
      "\n",
      "Iteration 4: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.96304476]\n",
      " [0.55412852]\n",
      " [0.44587486]\n",
      " [0.03695572]], \n",
      "current_gradient=[[3.86975513e-06]\n",
      " [5.84913906e-06]], \n",
      "current_hessian=[[0.56532012 0.25439413]\n",
      " [0.25439413 0.11612834]], \n",
      "w=[[  9.78227666]\n",
      " [-21.73839257]]\n",
      "\n",
      "Iteration 5: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.9630578 ]\n",
      " [0.55413297]\n",
      " [0.44586703]\n",
      " [0.0369422 ]], \n",
      "current_gradient=[[1.77507752e-10]\n",
      " [7.68851417e-10]], \n",
      "current_hessian=[[0.56529419 0.25438239]\n",
      " [0.25438239 0.11612247]], \n",
      "w=[[  9.78227684]\n",
      " [-21.73839298]]\n",
      "\n",
      "Iteration 6: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.9630578 ]\n",
      " [0.55413298]\n",
      " [0.44586702]\n",
      " [0.0369422 ]], \n",
      "current_gradient=[[4.16333634e-17]\n",
      " [4.98336439e-17]], \n",
      "current_hessian=[[0.56529419 0.25438238]\n",
      " [0.25438238 0.11612247]], \n",
      "w=[[  9.78227684]\n",
      " [-21.73839298]]\n",
      "\n",
      "Iteration 7: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.9630578 ]\n",
      " [0.55413298]\n",
      " [0.44586702]\n",
      " [0.0369422 ]], \n",
      "current_gradient=[[5.34294831e-16]\n",
      " [2.20530434e-16]], \n",
      "current_hessian=[[0.56529419 0.25438238]\n",
      " [0.25438238 0.11612247]], \n",
      "w=[[  9.78227684]\n",
      " [-21.73839298]]\n",
      "\n",
      "Iteration 8: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.9630578 ]\n",
      " [0.55413298]\n",
      " [0.44586702]\n",
      " [0.0369422 ]], \n",
      "current_gradient=[[-1.02001740e-15]\n",
      " [-4.42133934e-16]], \n",
      "current_hessian=[[0.56529419 0.25438238]\n",
      " [0.25438238 0.11612247]], \n",
      "w=[[  9.78227684]\n",
      " [-21.73839298]]\n",
      "\n",
      "Iteration 9: \n",
      "phi=[[1.   0.3 ]\n",
      " [1.   0.44]\n",
      " [1.   0.46]\n",
      " [1.   0.6 ]] \n",
      "y=[[0.9630578 ]\n",
      " [0.55413298]\n",
      " [0.44586702]\n",
      " [0.0369422 ]], \n",
      "current_gradient=[[5.34294831e-16]\n",
      " [2.20530434e-16]], \n",
      "current_hessian=[[0.56529419 0.25438238]\n",
      " [0.25438238 0.11612247]], \n",
      "w=[[  9.78227684]\n",
      " [-21.73839298]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.1.2\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\" The standard logistic function. np.exp also accepts arrays\"\"\"\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def gradient_of_error(phi, y, t):\n",
    "    \"\"\" Gradient (first-order derivatives) of the error function, see Bishop page 207, eq. 4.96 \"\"\"\n",
    "    return np.dot(phi.T, y - t)\n",
    "\n",
    "def hessian_of_error(phi, y):\n",
    "    \"\"\" Hessian (second-order derivatives) of the error function, see Bishop page 207, eq. 4.97 \"\"\"\n",
    "    R = np.diag(np.ravel(y * (1 - y)))\n",
    "    return np.dot(phi.T, np.dot(R, phi))\n",
    "\n",
    "\n",
    "w = np.array([ [1.0], [1.0] ]) # two-dimensional weight vector\n",
    "x = np.array([0.3, 0.44, 0.46, 0.6])\n",
    "t = np.array([ [1], [0], [1], [0] ]) # targets\n",
    "phi = np.array([ [1, x_element] for x_element in x ]) # feature vector\n",
    "\n",
    "for i in range(10):\n",
    "    y = sigmoid(np.dot(phi, w)) # class estimates\n",
    "    \n",
    "    current_gradient = gradient_of_error(phi, y, t)\n",
    "    current_hessian = hessian_of_error(phi, y)\n",
    "    \n",
    "    w = w - np.dot(np.linalg.inv(current_hessian), current_gradient)\n",
    "    \n",
    "    print(\"Iteration {}: \\nphi={} \\ny={}, \\ncurrent_gradient={}, \\ncurrent_hessian={}, \\nw={}\\n\".format(\n",
    "        i, phi, y, current_gradient, current_hessian, w))\n",
    "    \n",
    "# Converges after 6 iterations  \n",
    "# w=[[  9.78227684][-21.73839298]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
