\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\newlabel{eq:1}{{1}{1}{Exercise 1 - Logistic regression (weight 5)}{equation.0.1}{}}
\newlabel{eq:2}{{2}{1}{1.1.1}{equation.0.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sine and Cosine\relax }}{2}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:sine-cosine}{{1}{2}{Sine and Cosine\relax }{figure.caption.3}{}}
\newlabel{eq:3}{{3}{2}{1.1.2}{equation.0.3}{}}
\newlabel{eq:4}{{4}{2}{1.1.2}{equation.0.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Two class data for logistic regression\relax }}{5}{figure.caption.5}}
\newlabel{Fig:two-class-dataset}{{2}{5}{Two class data for logistic regression\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Scatter plot of two class data of exercise 1 - Part 2\relax }}{6}{figure.caption.7}}
\newlabel{Fig:1_2_1}{{3}{6}{Scatter plot of two class data of exercise 1 - Part 2\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Scatter plot of two class data with class probabilities\relax }}{7}{figure.caption.10}}
\newlabel{Fig:1_2_3}{{4}{7}{Scatter plot of two class data with class probabilities\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Gaussian function $Y = 3 \cdot \mathcal  {N}(\textbf  {0}|\frac  {2}{5}\textbf  {I}_2)$ graphed.\relax }}{9}{figure.caption.15}}
\newlabel{GausPlot}{{5}{9}{Gaussian function $Y = 3 \cdot \mathcal {N}(\textbf {0}|\frac {2}{5}\textbf {I}_2)$ graphed.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Inital output of the network for m = 8.\relax }}{10}{figure.caption.21}}
\newlabel{First}{{6}{10}{Inital output of the network for m = 8.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Output after 200 iterations of training.\relax }}{11}{figure.caption.23}}
\newlabel{Second}{{7}{11}{Output after 200 iterations of training.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Output after 2000 iterations of training.\relax }}{12}{figure.caption.24}}
\newlabel{Third}{{8}{12}{Output after 2000 iterations of training.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The error and time for various amount of hidden layers M. The time taken is fairly constant and the error seems to be constant after ~10-20 hidden layers. So it's best to take around 20 hidden layers.\relax }}{13}{figure.caption.27}}
\newlabel{Merror}{{9}{13}{The error and time for various amount of hidden layers M. The time taken is fairly constant and the error seems to be constant after ~10-20 hidden layers. So it's best to take around 20 hidden layers.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Errors for different values of $\eta $. A value around 0.1-1.5 seems to be the best.\relax }}{14}{figure.caption.28}}
\newlabel{EtaErr}{{10}{14}{Errors for different values of $\eta $. A value around 0.1-1.5 seems to be the best.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The bias on the random value of the inital weights. A bias of 0 seems to be the best.\relax }}{15}{figure.caption.29}}
\newlabel{WDif}{{11}{15}{The bias on the random value of the inital weights. A bias of 0 seems to be the best.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Multi-modal probability density\relax }}{15}{figure.caption.30}}
\newlabel{Fig:multi-modal}{{12}{15}{Multi-modal probability density\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Plot of the data.\relax }}{16}{figure.caption.32}}
\newlabel{2.5}{{13}{16}{Plot of the data.\relax }{figure.caption.32}{}}
\newlabel{eq:5}{{6}{16}{Exercise 3 - Gaussian processes (weight 5)}{equation.0.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Samples from Gaussian process prior using the Gram matrix with the $\theta 's$ given.\relax }}{18}{figure.caption.38}}
\newlabel{3.1.3}{{14}{18}{Samples from Gaussian process prior using the Gram matrix with the $\theta 's$ given.\relax }{figure.caption.38}{}}
\newlabel{eq:6}{{7}{21}{3.1.5}{equation.0.7}{}}
\newlabel{eq:7}{{8}{21}{Exercise 4 - EM and doping (weight 5)}{equation.0.8}{}}
\newlabel{eq:8}{{9}{22}{4.3}{equation.0.9}{}}
